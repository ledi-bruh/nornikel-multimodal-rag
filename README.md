# Мультимодальная RAG-система для работы с базой знаний Норникеля

![Логотип проекта](https://smart-lab.ru/uploads/2024/images/21/08/12/2024/02/12/4d9fa3.png)

## Описание проекта

Данный проект представляет собой мультимодальную Retrieval-Augmented Generation (RAG) систему, разработанную для работы с базой знаний компании Норникель. Система предназначена для обработки и извлечения информации из документов различных форматов (PDF, DOCX, TXT, PPTX, изображения и др.) и предоставления точных, контекстуально релевантных ответов на запросы пользователей. Основной язык системы — русский.

Система использует передовые модели машинного обучения, включая Vision-Language Models (VLM), и дообученные модели для работы с мультимодальными и многоязычными данными. В результате создана удобная и мощная платформа, которая позволяет пользователям взаимодействовать с базой знаний через чат-интерфейс.

---

## Проблематика

При разработке системы были выделены следующие ключевые задачи:

1. **Мультимодальная обработка данных**: Необходимость работы с документами различных форматов, включая текст, изображения и таблицы.
2. **Многоязычная поддержка**: База знаний содержит данные на русском языке, что требует адаптации моделей, изначально обученных на английском.
3. **Эффективный поиск**: Система должна быстро находить наиболее релевантные документы и предоставлять точные ответы.
4. **Масштабируемость**: Обработка большого объема данных без потери производительности.

---

## Решение

Для решения поставленных задач была разработана следующая стратегия:

### 1. **Формулировка гипотез**

- **Гипотеза 1**: Мультимодальная модель, обученная на английском языке, может быть дообучена для работы с русскоязычными данными.
- **Гипотеза 2**: Приведение всех документов к единому формату (PDF) упростит процесс обработки и повысит точность извлечения данных.
- **Гипотеза 3**: Комбинация нескольких моделей для этапов извлечения и генерации ответов обеспечит наилучшие результаты.

### 2. **Предобработка данных**

Для стандартизации и упрощения обработки все документы были конвертированы в формат PDF (поскольку любой из треубемых форматов легко приводится к PDF). На этапе предобработки из документов извлекались следующие метаданные:

- Название файла
- URL документа
- Язык документа
- Описание страниц
- Наличие таблиц, рисунков и абзацев
- Номер страницы
- Тип запроса и его модальность
- Логические цепочки для генерации запросов

Эти данные использовались для создания обучающего датасета с помощью модели **GPT-4-o mini**. И конечный датасет включал в себя следующие поля:

- document_filename: имя файла документа.
- document_url: исходный URL документа.
- search_query: запрос, используемый для получения документа.
- search_topic: тема, связанная с документом.
- search_subtopic: подтема, относящаяся к документу.
- search_language: язык, указанный для поиска.
- search_filetype: фильтр по типу файла, применяемый при поиске.
- page_number: номер страницы в документе.
- page_description: описание страницы на естественном языке.
- page_language: язык, используемый на странице.
- page_contains_table: логическое значение, указывающее на наличие таблиц.
- page_contains_figure: логическое значение, указывающее на наличие рисунков.
- page_contains_paragraph: логическое значение, указывающее на наличие абзацев.
- page_image: изображение страницы в формате jpg
- query_type: тип запроса (например, извлекающий, открытый, логический, сравнивающий-контрастный, перечисляющий, числовой).
- query_answerability: уровень отвечаемости запроса (полностью отвечаемый, частично отвечаемый, без ответа).
- query_modality: модальность, используемая для генерации запроса.
- query_language: язык, на котором выполняется запрос.
- query_reasoning: логические цепочки, используемые при генерации запроса.
- query: фактический текст запроса.
- query_is_self_contained: логическое значение, указывающее, является ли запрос автономным.
- query_is_self_contained_reasoning: логические цепочки для определения автономного характера.
- answer: ожидаемый ответ на вопрос из поля "запрос".

### 3. **Выбор и дообучение моделей**

#### **Модель для извлечения данных (Retriever)**

В качестве базовой модели была выбрана **Vidore/ColQwen2-v1.0**, так как эта модель является лучшей для задачи Visual Document Retrieval по большому количеству различных метрик (ссылка на бэнчмарк: https://huggingface.co/spaces/vidore/vidore-leaderboard), которая генерирует многовекторные представления текста и изображений. Однако, поскольку модель изначально оптимизирована для английского языка, она была дообучена на русскоязычном датасете, включающем данные из базы знаний Норникеля. 

Особенности дообучения:
- Использование метаданных для улучшения индексации документов.
- Включение логических цепочек для повышения качества обработки запросов.
- Адаптация модели для работы с изображениями и таблицами на русском языке.

#### **Модель для генерации ответов (Reasoner)**

Для генерации ответов была выбрана модель **Qwen2-VL-7B-Instruct**, которая обрабатывает топ-k релевантных документов, найденных ретривером, и формирует детализированный ответ на основе контекста.

### 4. **Архитектура системы**

Система состоит из следующих компонентов:

1. **Модуль предобработки**: Конвертирует документы в PDF, извлекает метаданные и создает векторные представления.
2. **Ретривер**: Использует дообученную модель ColQwen для поиска релевантных документов.
3. **Генератор ответов**: Обрабатывает найденные документы и формирует ответ на запрос пользователя.
4. **Чат-интерфейс**: Удобный графический интерфейс для взаимодействия с системой.

---

## Ключевые особенности

- **Мультимодальная поддержка**: Работа с текстами, изображениями, таблицами и другими форматами.
- **Многоязычность**: Оптимизация для русского языка.
- **Высокая точность**: Комбинация моделей для извлечения и генерации ответов.
- **Интуитивный интерфейс**: Чат для взаимодействия с базой знаний.
- **Масштабируемость**: Возможность обработки больших объемов данных.

---

## Методология и эксперименты

### Исследование методов

На этапе разработки были протестированы различные подходы:

1. **Базовые модели**: Использование оригинальных моделей ColQwen и Qwen2-VL без дообучения показало недостаточно высокую точность на русскоязычных данных.
2. **Альтернативные архитектуры**: Модели BLIP и Flamingo были протестированы, но не обеспечили необходимой точности для данной предметной области.
3. **Генерация синтетических данных**: Использование GPT-4-o mini для создания обучающего датасета значительно улучшило результаты.

### Результаты

После дообучения и оптимизации система показала высокую точность извлечения и генерации ответов. Тестирование на реальных запросах пользователей подтвердило эффективность выбранного подхода.

Все результаты были оценены империческим методом.

## Инструкция по запуску

1. Склонируйте проект

```
git clone https://github.com/ledi-bruh/nornikel-multimodal-rag.git
```

2. Перейдите в папку со склонированным репозиторием

3. Переименуйте файл `.env.example` в `.env` и заполните необходимые переменные

4. Соберите образы

```
docker compose build
```

5. Запустите контейнеры

```
docker compose up
```

В первый запуск будут загружаться модели, поэтому придется подождать.


Запуск frontend части:

0. Скачать node@20.11.0

1. `cd frontend/nornickel-chat` и Переименуйте файл `.env.example` в `.env` и заполните необходимые переменные

2. `npm install`

3. `npm run dev`


### Решение развернуто

frontend http://176.99.130.189:5173/
backend swagger http://176.99.130.189:8558/docs
db http://176.99.130.189:6333/dashboard
